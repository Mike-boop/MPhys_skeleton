{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "\n",
    "- plots for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import h5py\n",
    "import os\n",
    "import models\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import data_generators\n",
    "import train_network\n",
    "from etmiss_utils import get_etmiss\n",
    "\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data/sample_00_fixed.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_test = 100\n",
    "sk = f[\"SK\"][:number_to_test]\n",
    "cssk = f[\"CSSK\"][:number_to_test]\n",
    "cluster = f[\"cluster\"][:number_to_test]\n",
    "vsk = f[\"VorSK\"][:number_to_test]\n",
    "X = np.asarray([cluster, sk, vsk, cssk])\n",
    "X = np.moveaxis(X, 0, -1)\n",
    "X = np.expand_dims(X, 1)\n",
    "\n",
    "Y = f[\"truth_nm_barcode\"][:number_to_test]\n",
    "Y = [get_etmiss(y[:, np.newaxis]) for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "mdl = models.BB_model(tracks=False)\n",
    "mdl.load_weights(\"trained_models/2604_tracksFalse_2020-11-01__weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_predictions = np.asarray([mdl.predict(x) for x in X])[:,0,:,:,0]\n",
    "met_predictions = [get_etmiss(x[:, np.newaxis]) for x in met_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_etmiss = Y - np.asarray(met_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(met_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "spec = gridspec.GridSpec(ncols=1, nrows=4, figure=fig, hspace=0)\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "ax2 = fig.add_subplot(spec[1:3, 0])\n",
    "ax3 = fig.add_subplot(spec[3, 0])\n",
    "\n",
    "ax1.axes.tick_params(axis=\"x\", bottom=False, labelbottom=False)\n",
    "ax2.axes.tick_params(axis=\"x\", bottom=False, labelbottom=False)\n",
    "\n",
    "ax1.set_ylabel(\"#Events\")\n",
    "ax2.set_ylabel(\"$\\Delta E_T^\\mathrm{miss}$ $[GeV]$\")\n",
    "ax3.set_xlabel(\"$E_T^\\mathrm{miss}$ $[GeV]$\")\n",
    "ax3.set_ylabel(\"$\\\\frac{\\mathrm{SK}}{\\mathrm{NN}}$\")\n",
    "\n",
    "ax1.hist(Y)\n",
    "ax2.plot(delta_etmiss)\n",
    "ax3.plot(np.asarray([get_etmiss(s) for s in sk])/met_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract weights of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = mdl.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(w[:,:,0,0])\n",
    "plt.ylabel(\"phi bins\")\n",
    "plt.xlabel(\"eta bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activation of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "sk = f[\"SK\"][index]\n",
    "cssk = f[\"CSSK\"][index]\n",
    "cluster = f[\"cluster\"][index]\n",
    "vsk = f[\"VorSK\"][index]\n",
    "X = np.asarray([sk, cssk, vsk, cluster])\n",
    "X = np.moveaxis(X, 0, -1)\n",
    "X = np.expand_dims(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_model = Model(inputs=mdl.input,\n",
    "                                 outputs=mdl.get_layer('conv2d').output)\n",
    "first_layer_activation = first_layer_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(first_layer_activation[0,:,:,0]))\n",
    "cb =  plt.colorbar()\n",
    "\n",
    "cb.ax.set_ylabel(\"ET [GeV]\")\n",
    "plt.xlabel(\"$\\eta$\")\n",
    "plt.ylabel(\"$\\phi$\")\n",
    "\n",
    "plt.yticks([0, 31, 63], [\"$-\\pi$\", \"$0$\", \"$\\pi$\"])\n",
    "plt.xticks([0, 24, 49], [\"$-2.5$\", \"$0$\", \"$2.5$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient ascent input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 3  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 20  # Number of ascent steps per scale\n",
    "max_loss = 15.0\n",
    "\n",
    "outputs_dict = dict(\n",
    "    [\n",
    "        (layer.name, layer.output)\n",
    "        for layer in mdl.layers\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set up a model that returns the activation values for every target layer\n",
    "# (as a dict)\n",
    "feature_extractor = Model(inputs=mdl.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(input_image):\n",
    "    features = feature_extractor(input_image)\n",
    "    # Initialize the loss\n",
    "    loss = tf.zeros(shape=())\n",
    "    for name in features.keys():\n",
    "        coeff = 1\n",
    "        activation = features[name]\n",
    "        # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "        scaling = tf.reduce_prod(tf.cast(tf.shape(activation), \"float32\"))\n",
    "        loss += coeff * tf.reduce_sum(tf.square(activation[:, 2:-2, 2:-2, :])) / scaling\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent_step(img, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img)\n",
    "        loss = compute_loss(img)\n",
    "    # Compute gradients.\n",
    "    grads = tape.gradient(loss, img)\n",
    "    # Normalize gradients.\n",
    "    grads /= tf.maximum(tf.reduce_mean(tf.abs(grads)), 1e-6)\n",
    "    img += learning_rate * grads\n",
    "    return loss, img\n",
    "\n",
    "def gradient_ascent_loop(img, iterations, learning_rate, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss, img = gradient_ascent_step(img, learning_rate)\n",
    "        if max_loss is not None and loss > max_loss:\n",
    "            break\n",
    "        print(\"... Loss value at step %d: %.2f\" % (i, loss))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "original_img = deepcopy(X)\n",
    "original_shape = original_img.shape[1:3]\n",
    "\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])\n",
    "\n",
    "img = tf.identity(original_img)  # Make a copy\n",
    "for i, shape in enumerate(successive_shapes):\n",
    "    print(\"Processing octave %d with shape %s\" % (i, shape))\n",
    "    img = tf.image.resize(img, shape)\n",
    "    img = gradient_ascent_loop(\n",
    "        img, iterations=iterations, learning_rate=step, max_loss=max_loss\n",
    "    )\n",
    "    upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)\n",
    "    same_size_original = tf.image.resize(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = tf.image.resize(original_img, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(img[0,:,:,3]))\n",
    "cb =  plt.colorbar()\n",
    "\n",
    "cb.ax.set_ylabel(\"ET [GeV]\")\n",
    "plt.xlabel(\"$\\eta$\")\n",
    "plt.ylabel(\"$\\phi$\")\n",
    "\n",
    "plt.yticks([0, 31, 63], [\"$-\\pi$\", \"$0$\", \"$\\pi$\"])\n",
    "plt.xticks([0, 24, 49], [\"$-2.5$\", \"$0$\", \"$2.5$\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
