{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import neural_network\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import etmiss_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use file locking. This means you can run jobs concurrently.\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "\n",
    "- data were stored as .h5 files for this project. Gabriel (AJB student) may be able to provide some example data or an ntuple->h5 workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\"data/sample_00_fixed.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .h5 file must contain PU-corrected calorimeter images (SK, CSSK, etc.) and a 'truth image' (e.g. truth_barcode). Check what fields you have available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys() # what fields are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = 2\n",
    "plt.imshow(np.transpose(data[\"SK\"][entry]))\n",
    "\n",
    "cb =  plt.colorbar()\n",
    "cb.ax.set_ylabel(\"ET [GeV]\")\n",
    "plt.xlabel(\"$\\eta$\")\n",
    "plt.ylabel(\"$\\phi$\")\n",
    "\n",
    "plt.yticks([0, 31, 63], [\"$-\\pi$\", \"$0$\", \"$\\pi$\"])\n",
    "plt.xticks([0, 24, 49], [\"$-2.5$\", \"$0$\", \"$2.5$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the MET from individual input channels (SK, CSSK,...) is calculated and fed into a non-convolutional classifier. Change num_entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"SK\", \"VorSK\", \"CSSK\", \"cluster\"]\n",
    "\n",
    "def extract_features(dataset):\n",
    "    num_entries = 100#dataset[\"entries\"][0]\n",
    "    num_features = len(features)\n",
    "    X = np.empty((num_entries, num_features))\n",
    "    y = np.empty((num_entries))\n",
    "    for i in range(num_entries):\n",
    "        for j, feature in enumerate(features):\n",
    "            tmp = etmiss_utils.get_etmiss((dataset[feature][i][:, np.newaxis]))\n",
    "            X[i][j] = tmp\n",
    "        y[i] = etmiss_utils.get_etmiss((dataset[\"truth_nm_barcode\"][i][:, np.newaxis]))\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PU algorithms correlate fairly well with the truth MET (good!)\n",
    "The lower the MET threshold, the harder the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], y)\n",
    "plt.xlabel(\"SoftKiller MET [GeV]\")\n",
    "plt.ylabel(\"Truth MET [GeV]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a threshold of 50 GeV\n",
    "Y = y>50\n",
    "Y = Y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the imbalance here. Not too good.\n",
    "plt.hist(Y)\n",
    "plt.xticks([0,1], [\"Low MET\", \"High MET\"])\n",
    "plt.ylabel(\"Num Events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Get class imbalance\n",
    "length = len(Y)\n",
    "num_high_met = sum(Y)\n",
    "\n",
    "#2. Randomly choose some low-met events to get rid of\n",
    "indices_low = np.argwhere(Y==0)[:,0]\n",
    "indices_high = np.argwhere(Y==1)[:,0]\n",
    "low_met_indices_to_keep = np.random.choice(indices_low, num_high_met)\n",
    "\n",
    "#3. Fix the imbalance\n",
    "Y = Y[np.concatenate([low_met_indices_to_keep, indices_high])]\n",
    "X = X[np.concatenate([low_met_indices_to_keep, indices_high])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y)\n",
    "plt.xticks([0,1], [\"Low MET\", \"High MET\"])\n",
    "plt.ylabel(\"Num Events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.05 #test on 20% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set Up Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_zoo = {\n",
    "    'XGradientBoostTrees':xgboost.XGBClassifier,\n",
    "    'DecisionTree': tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=55),\n",
    "    'AdaBoostTrees': ensemble.AdaBoostClassifier(n_estimators=85),\n",
    "    'NaiveBayes':naive_bayes.GaussianNB(),\n",
    "    'RFTrees':ensemble.RandomForestClassifier(n_estimators=270, max_depth=80, criterion=\"gini\"),\n",
    "    'LogisticRegressor':linear_model.LogisticRegression(),\n",
    "    'MLP':neural_network.MLPClassifier(hidden_layer_sizes=(50,100,50), activation=\"tanh\", solver=\"adam\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing tools that I used are demonstrated below (commented out right now). PowerTransformer does a box-cox transformation to make the data look gaussian (this is useful for the MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "power = PowerTransformer(method=\"box-cox\", standardize=True, copy=True)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#X_tr = power.fit_transform(X_train)\n",
    "#X_tr = pca.fit_transform(X_train)\n",
    "X_tr = X_train\n",
    "\n",
    "#X_te = power.transform(X_test)\n",
    "#X_te = pca.transform(X_test)\n",
    "X_te = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = algo_zoo[\"MLP\"]\n",
    "clf.fit(X_tr, y_train)\n",
    "predictions = clf.predict_proba(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, predictions[:,0])\n",
    "plt.plot(tpr, fpr)\n",
    "plt.xlabel(\"True +ve Rate\")\n",
    "plt.ylabel(\"False +ve Rate\")\n",
    "plt.legend([roc_auc_score(y_test, predictions[:,1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Try to understand models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the features (SK, VorSK, CSSK, cluster) contribute to the principal components?\n",
    "The features must be standardised so the pca coefficients can be compared directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of the total variance does each component explain? The most useful component appears to be the mean MET (more or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the relative importances of the input features for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(clf):\n",
    "    clf_type = type(clf).__name__.split(\".\")[-1]\n",
    "    if clf_type == \"MLPClassifier\":\n",
    "        # sum of the (absolute) input weights from each feature.\n",
    "        # There are more sophisticated ways of assessing feature importance though.\n",
    "        return np.sum(np.abs(clf.coefs_[0]), axis=1)\n",
    "    if clf_type in {\"DecisionTreeClassifier\", \"AdaBoostClassifier\", \"RandomForestClassifier\", \"XGBClassifier\"}:\n",
    "        # Uses a purity-based estimate of feature importance.\n",
    "        return clf.feature_importances_\n",
    "    if clf_type == \"GaussianNB\":\n",
    "        return # you could do a permutation test here\n",
    "    if clf_type == \"LogisticRegression\":\n",
    "        # feature coeficients as used in the decision function.\n",
    "        return clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model to optimise\n",
    "mdl = ensemble.AdaBoostClassifier()\n",
    "# choose a grid of hyperparameters to search\n",
    "param_grid = {\"n_estimators\":[50,100,150]}\n",
    "# do the fit\n",
    "clf = GridSearchCV(mdl, param_grid, verbose=1)\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
